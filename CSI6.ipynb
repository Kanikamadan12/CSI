{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0e2def-16c7-40e5-82fd-554d145e430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LogisticRegression ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "--- RandomForest ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "--- SVM ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "--- KNN ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Best Tuned RandomForest:\n",
      "--- RandomForest (Tuned) ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Best Tuned SVM:\n",
      "--- SVM (Tuned) ---\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "\n",
      "--- Final Model Comparison ---\n",
      "                Model  Accuracy  Precision  Recall  F1 Score\n",
      "0  LogisticRegression       1.0        1.0     1.0       1.0\n",
      "1        RandomForest       1.0        1.0     1.0       1.0\n",
      "2                 SVM       1.0        1.0     1.0       1.0\n",
      "3                 KNN       1.0        1.0     1.0       1.0\n",
      "4  RandomForest_Tuned       1.0        1.0     1.0       1.0\n",
      "5           SVM_Tuned       1.0        1.0     1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 2: Load and Split Dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Define Models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Step 4: Train and Evaluate Models\n",
    "def evaluate_model(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print()\n",
    "\n",
    "for name, model in models.items():\n",
    "    evaluate_model(name, model)\n",
    "\n",
    "# Step 5: Hyperparameter Tuning using GridSearchCV and RandomizedSearchCV\n",
    "\n",
    "# RandomForest - GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [2, 4, 6, None]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM - RandomizedSearchCV\n",
    "param_dist_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "rand_svm = RandomizedSearchCV(SVC(), param_distributions=param_dist_svm, n_iter=5, cv=5, random_state=42)\n",
    "rand_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Best Tuned Models\n",
    "print(\"Best Tuned RandomForest:\")\n",
    "evaluate_model(\"RandomForest (Tuned)\", grid_rf.best_estimator_)\n",
    "\n",
    "print(\"Best Tuned SVM:\")\n",
    "evaluate_model(\"SVM (Tuned)\", rand_svm.best_estimator_)\n",
    "\n",
    "# Final Model Selection\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}\n",
    "\n",
    "all_models = {\n",
    "    'LogisticRegression': models['LogisticRegression'],\n",
    "    'RandomForest': models['RandomForest'],\n",
    "    'SVM': models['SVM'],\n",
    "    'KNN': models['KNN'],\n",
    "    'RandomForest_Tuned': grid_rf.best_estimator_,\n",
    "    'SVM_Tuned': rand_svm.best_estimator_\n",
    "}\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    results[\"Precision\"].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    results[\"Recall\"].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    results[\"F1 Score\"].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Display Results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n--- Final Model Comparison ---\")\n",
    "print(df_results.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3adcbd-926d-4cc5-ab3b-16314edf3c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
